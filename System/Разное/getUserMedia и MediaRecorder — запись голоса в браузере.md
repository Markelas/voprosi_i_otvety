# getUserMedia и MediaRecorder — запись голоса в браузере

## Краткий ответ для собеседования

**getUserMedia** — API для доступа к медиа-устройствам (микрофон, камера): вызываешь `navigator.mediaDevices.getUserMedia({ audio: true })`, пользователь даёт разрешение, возвращается **MediaStream** — поток аудио (или видео) в реальном времени. **MediaRecorder** — API для записи этого потока: создаёшь рекордер из MediaStream, запускаешь запись, получаешь куски данных (чаще всего в формате **Blob** в выбранном контейнере, например WebM/Opus). После записи Blob можно отправить на сервер, обработать через Web Audio API или передать в сервисы распознавания речи. Важно: getUserMedia и MediaRecorder работают только в **безопасном контексте** (HTTPS или localhost); пользователь должен явно разрешить доступ. На собеседовании: что даёт каждый API, как связаны, что на выходе, ограничения и типичная обработка после записи.

---

## getUserMedia — доступ к микрофону (и камере)

**Что это:** метод `navigator.mediaDevices.getUserMedia(constraints)` запрашивает у пользователя доступ к медиа-устройствам и возвращает **Promise** с объектом **MediaStream**. Поток содержит треки (аудио и/или видео) с устройства.

**Ограничения (constraints):** в объекте указывают, что нужно: только звук `{ audio: true }`, только видео `{ video: true }` или оба. Можно уточнить качество: например, частота дискретизации для аудио, разрешение для видео. Браузер попытается выполнить ограничения; если не получится — вернёт поток с доступными настройками или отклонит Promise.

**Важно:**
- Работает только в **безопасном контексте**: HTTPS или `localhost` (в старых браузерах только HTTPS).
- Пользователь **обязательно** должен нажать «Разрешить» в диалоге браузера; без разрешения Promise будет отклонён (NotAllowedError).
- После использования поток нужно **остановить**: у каждого трека вызвать `track.stop()`, иначе индикатор доступа к микрофону остаётся активным и устройство занято.

**На выходе:** объект **MediaStream**. Его можно передать в **MediaRecorder** для записи, в **AudioContext** (Web Audio API) для анализа или эффектов, или вывести в `<audio>`/`<video>` для предпросмотра.

---

## MediaRecorder — запись потока в файл (Blob)

**Что это:** **MediaRecorder** принимает **MediaStream** и записывает его в выбранном формате. Запись идёт кусками (чанками); по окончании или по порциям получаешь **Blob** — бинарные данные записи (аудио/видео в контейнере, например WebM с Opus для аудио).

**Как используется:**
- Создать рекордер: `new MediaRecorder(stream, options)`. В options можно указать **mimeType** (например, `audio/webm;codecs=opus`) и **audioBitrate**.
- **start()** — начать запись. Можно вызывать **start(timeslice)** — тогда каждые `timeslice` миллисекунд будет срабатывать событие **dataavailable** с очередным Blob.
- Событие **dataavailable** — в нём приходит кусок записанных данных (Blob). Его можно складывать в массив или сразу отправлять на сервер (chunked upload).
- **stop()** — остановить запись. После stop последний раз сработает **dataavailable** с финальным куском (если что-то осталось в буфере).
- Итог: один или несколько **Blob**, которые можно объединить в один файл, отдать в **FormData** для загрузки на сервер или передать в **AudioContext** / другие API для обработки.

**Форматы:** браузер поддерживает ограниченный набор. Для голоса часто используют `audio/webm;codecs=opus` или `audio/mp4` (поддержка по браузерам разная). Проверка: `MediaRecorder.isTypeSupported(mimeType)`.

---

## Связка: запись голоса и дальнейшая обработка

Типичный поток:

1. **getUserMedia({ audio: true })** → получаем **MediaStream** с микрофона.
2. **new MediaRecorder(stream)** → создаём рекордер, подписываемся на **dataavailable**, вызываем **start()**.
3. Пользователь говорит; по окончании вызываем **stop()** → в **dataavailable** (и при stop) получаем **Blob**(ы) с записью.
4. **Обработка после записи:**
   - **Отправка на сервер** — Blob положить в **FormData**, отправить через **fetch** (POST). Сервер сохраняет файл или передаёт в сервис распознавания (Speech-to-Text).
   - **Локальная обработка** — из Blob создать URL (**URL.createObjectURL**) и передать в **AudioContext** для анализа (громкость, спектр) или воспроизведения.
   - **Распознавание в браузере** — Web Speech API **SpeechRecognition** работает с живым потоком; для уже записанного файла обычно нужен сервер или внешний сервис, куда отправляют Blob.

**Важно:** после записи не забыть остановить треки потока (`stream.getTracks().forEach(t => t.stop())`), чтобы освободить микрофон.

---

## Ограничения и нюансы

| Аспект | Пояснение |
|--------|------------|
| **HTTPS / localhost** | getUserMedia и MediaRecorder доступны только в безопасном контексте. На HTTP (кроме localhost) не работают. |
| **Разрешение пользователя** | Без согласия пользователя поток не получить; при отказе — ошибка в Promise. |
| **Форматы записи** | Поддержка MIME-типов различается по браузерам. Проверять через `MediaRecorder.isTypeSupported()`. |
| **Остановка потока** | Треки нужно явно останавливать (`track.stop()`), иначе индикатор доступа и занятость устройства остаются. |
| **Размер и длительность** | Длинные записи дают большие Blob; для очень долгих записей удобнее отправлять чанки по **dataavailable** (start(timeslice)) на сервер по мере записи. |

---

## Вопросы на собеседовании

| Вопрос | Краткий ответ |
|--------|----------------|
| Что такое getUserMedia? | API для доступа к микрофону/камере: возвращает Promise с MediaStream после разрешения пользователя. Работает только в HTTPS/localhost. |
| Что такое MediaRecorder? | API для записи MediaStream: создаётся из потока, start()/stop(), в событии dataavailable приходят Blob с записанными данными (аудио/видео в выбранном формате). |
| Как связаны getUserMedia и MediaRecorder? | getUserMedia даёт MediaStream с микрофона; этот поток передают в new MediaRecorder(stream); рекордер пишет поток в Blob, которые потом можно отправить или обработать. |
| Что на выходе записи голоса? | Blob (или несколько при использовании timeslice) — бинарные данные в формате контейнера (часто audio/webm;codecs=opus). Их отправляют на сервер или обрабатывают через Web Audio API. |
| Как обработать запись после MediaRecorder? | Blob отправить на сервер (FormData + fetch) для сохранения или распознавания речи; или создать Object URL и передать в AudioContext для анализа/воспроизведения. |
| Какие ограничения у записи в браузере? | Только безопасный контекст (HTTPS/localhost); обязательное разрешение пользователя; поддержка форматов зависит от браузера; нужно явно останавливать треки потока. |

---

## Кратко запомнить

- **getUserMedia** — доступ к микрофону (и камере), на выходе **MediaStream**; только HTTPS/localhost и разрешение пользователя.
- **MediaRecorder** — запись MediaStream в **Blob** по кускам (событие **dataavailable**); start()/stop(), формат задаётся mimeType.
- Типичная цепочка: getUserMedia → MediaStream → MediaRecorder → запись → Blob → отправка на сервер или обработка (Web Audio API, распознавание на бэкенде).
- После использования — остановить треки потока (track.stop()), проверить поддержку формата через isTypeSupported().
